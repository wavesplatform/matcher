waves.dex {
  # DEX base directory
  root-directory = ${user.dir}

  # A directory for database
  data-directory = ${waves.dex.root-directory}"/data"

  # Secure keys
  secure-keys = [
    "user", "pass", "seed", "private", "java", "sun", "api"
  ]

  # A unique in cluster matcher's id. It appears in HTTP responses.
  # It is recommended to change to matcher-1, matcher-2, ... in a cluster setup.
  id = "default"

  # W - mainnet, T - testnet, S - stagenet, D - devnet
  address-scheme-character = "D"

  # An account storage
  account-storage {

    type = "not-specified" # "in-mem" or "encrypted-file"
    in-mem.seed-in-base-64 = ""

    encrypted-file {
      path = "/path/to/account.dat"
      password = "password-for-file"
    }
  }

  # NTP server
  ntp-server = "pool.ntp.org"

  # Matcher REST API settings
  rest-api {
    # Bind address
    address = "127.0.0.1"

    # Bind port
    port = 6880

    # Hash of API key in the Base58 encoding
    api-key-hash = ""

    # Enable/disable CORS support
    # If you want to access DEX Server REST API from the other hosts in a browser, otherwise set to "no"
    cors = yes

    # Enable/disable X-API-Key from different host
    # If enabled, a client from other hosts can pass X-Api-Key in a browser and therefore has an access to the private API
    api-key-different-host = no
  }

  # Address settings
  address-actor {
    # Maximum number of active orders
    max-active-orders = 400
  }

  order-db {
    # Maximum number of finalized orders in the order db. Older orders are removed
    max-orders = 100
  }

  # Client to Waves DEX extension
  waves-blockchain-client {

    # Settings for gRPC which is used by the client to interact with Waves DEX extension.
    # Client for com.wavesplatform.dex.grpc.integration.DEXExtension
    grpc {
      # Address and port of gRPC server.
      # In order to provide fault-tolerance, consider using DNS server between DEX and Node, which would resolve this
      # address into several endpoints (ips of nodes with DEXExtension installed).
      # Use "dns:///" prefix to specify a domain name
      target = "127.0.0.1:6887"

      # Internal gRPC channel settings

      # Sets max number of hedged attempts.
      # Hedging means sending multiple copies of a single request without waiting for a response.
      max-hedged-attempts = 5

      # Sets max number of retry attempts
      max-retry-attempts = 30

      # Sets whether keepalive will be performed when there are no outstanding RPC on a connection
      keep-alive-without-calls = true

      # Sets the time without read activity before sending a keepalive ping.
      # Can't be less than 10s, see io.grpc.internal.KeepAliveManager
      keep-alive-time = 10s

      # Sets the time waiting for read activity after sending a keepalive ping.
      keep-alive-timeout = 5s

      # Set the duration without ongoing RPCs before going to idle mode.
      # See https://github.com/grpc/grpc/blob/master/doc/connectivity-semantics-and-api.md
      idle-timeout = 300d

      # Low level settings for connection
      channel-options {
        # A timeout to setup a connection
        connect-timeout = 5s
      }

      # Not used right now
      no-data-timeout = 1m
    }

    # Settings for gRPC which is used by the client to interact with Blockchain updates extension.
    # Client for com.wavesplatform.events.BlockchainUpdates
    blockchain-updates-grpc {
      # Address and port of gRPC server.
      # In order to provide fault-tolerance, consider using DNS server between DEX and Node, which would resolve this
      # address into several endpoints (ips of nodes with DEXExtension installed).
      # Use "dns:///" prefix to specify a domain name
      target = "127.0.0.1:6881"

      # Internal gRPC channel settings

      # Sets max number of hedged attempts.
      # Hedging means sending multiple copies of a single request without waiting for a response.
      max-hedged-attempts = 5

      # Sets max number of retry attempts
      max-retry-attempts = 30

      # Sets whether keepalive will be performed when there are no outstanding RPC on a connection
      keep-alive-without-calls = false

      # Sets the time without read activity before sending a keepalive ping.
      # Can't be less than 10s, see io.grpc.internal.KeepAliveManager
      keep-alive-time = 10s

      # Sets the time waiting for read activity after sending a keepalive ping.
      keep-alive-timeout = 5s

      # Set the duration without ongoing RPCs before going to idle mode.
      # See https://github.com/grpc/grpc/blob/master/doc/connectivity-semantics-and-api.md
      idle-timeout = 300d

      # Low level settings for connection
      channel-options {
        # A timeout to setup a connection
        connect-timeout = 5s
      }

      # HACK to reset a connection if we aren't getting data during this time
      no-data-timeout = 1m
    }

    # Сache settings used for temporary storage of node resuqst results
    # Default expiration time for each cache record
    default-caches-expiration = 100ms

    # A client that aggregates the data from matcher extensions and blockchain updates extension
    combined-client-settings {
      # How many blocks we need to store.
      # The optimal value is 100.
      # If you want to reduce a memory consumption, reduce this value, e.g. to 10.
      max-rollback-height = 100

      # HACK for Node behavior.
      # We need to store last updates and consider them as fresh, because we can face an issue during balances retrieving,
      #  when balance changes were deleted from LiquidBlock's diff, but haven't yet saved to DB.
      # Block updates are collected during blocks and micro blocks application.
      # 12 micro blocks is an average number for each blocks, thus we preserve the data during the minute.
      max-cached-latest-block-updates = 12

      # A delay before streams start during recovery or a manual restart due to unexpected events (should not happen).
      combined-stream.restart-delay = 1s

      # A number of saved confirmed transactions.
      # It solves some situations when a transaction observed as confirmed before it observed as added to Utx.
      pessimistic-portfolios.max-confirmed-transactions = 10000
    }
  }

  # Base fee for the exchange transaction
  exchange-tx-base-fee = 300000

  # Settings for DEX's fee in order: start-offset -> fee settings.
  #
  # Note:
  #  1. settings should be nonempty and must contain value for the current matcher offset;
  #  2. offsets start from -1
  #
  # Example:
  #
  # order-fee {
  #   -1: {
  #     mode = dynamic
  #     dynamic {
  #       base-maker-fee = 300000
  #       base-taker-fee = 300000
  #     }
  #   }
  #   100: {
  #     mode = dynamic
  #     dynamic {
  #       base-maker-fee = 100000
  #       base-taker-fee = 500000
  #     }
  #   }
  #   500: {
  #     mode = percent
  #     percent {
  #       asset-type = "amount"
  #       min-fee = 0.1
  #     }
  #   }
  # }
  order-fee {
    -1: {
      # Fee in:
      #  - some asset from the predefined list of the rated assets (dynamic) or
      #  - fixed asset and fee (fixed) or
      #  - percent fee in asset of the pair (percent)
      mode = "dynamic" # | "fixed" | "percent"

      # In this mode DEX charges additional fee for its
      # account script and scripts of the assets of the pair (if exists).
      # Matcher accepts fee in several assets which can be obtained by
      # the following REST request: GET /matcher/settings/rates
      # Fee is charged according to the asset rate (price of 1 Waves in that asset)
      dynamic {
        # Fee for maker order
        base-maker-fee = 300000
        # fee for taker order
        base-taker-fee = 300000
      }

      fixed {
        # Fixed fee asset
        asset = "WAVES" # | "some issued asset (base58)"
        # Minimum allowed order fee for fixed mode
        min-fee = 300000
      }

      percent {
        # Asset type for fee
        asset-type = "amount" # | "price" | "spending" | "receiving"
        # In percents
        min-fee = 0.1
      }
    }
  }

  # Price and fee deviations (in percents).
  # If enabled, imposes the following restrictions:
  #
  #   For BUY orders:
  #     1. (1 - p) * best bid <= price <= (1 + l) * best ask
  #     2. fee >= fs * (1 - fd) * best ask * amount
  #
  #   For SELL orders:
  #     1. (1 - l) * best bid <= price <= (1 + p) * best ask
  #     2. fee >= fs * (1 - fd) * best bid * amount
  #
  # where:
  #
  #   p  = max-price-deviations.max-price-profit  / 100
  #   l  = max-price-deviations.max-price-loss    / 100
  #   fd = max-price-deviations.max-fee-deviation / 100
  #   fs = order-fee.percent.min-fee              / 100
  #
  #   best bid = highest price of buy
  #   best ask = lowest price of sell
  #
  # Fee restrictions (2) checks if fee is in deviation bounds, i.e. orders's fee is higher than the specified
  # percentage of fee, which client would pay for the matching with the best counter order.
  #
  # NOTE:
  #  - price restrictions (1) are applicable to any mode,
  #  - fee restrictions (2) are only applicable to the percent order fee mode (order-fee.mode = percent, see order-fee settings)
  max-price-deviations {
    # Enable/disable deviations checks
    enable = no
    # Max price deviation IN FAVOR of the client
    max-price-profit = 1000000
    # Max price deviation AGAINST the client
    max-price-loss = 1000000
    # Max fee deviation from the market price
    max-fee-deviation = 1000000
  }

  # Restrictions for the orders. Empty list means that there are no restrictions on the orders
  #
  # Example:
  #
  # order-restrictions = {
  #   "WAVES-8LQW8f7P5d5PZM7GtZEBgaqRPGSzS3DfPuiXrURJ4AJS": {
  #     min-amount  = 0.001
  #     max-amount  = 1000000
  #     step-amount = 0.00000001
  #     min-price   = 0.001
  #     max-price   = 100000
  #     step-price  = 0.00000001
  #   },
  #   ...
  # }
  order-restrictions = {}

  # Matching rules' dictionary for asset pairs: pair -> rules.
  #
  # Rule:
  #
  # {
  #   start-offset = 100   # start offset to apply the rule
  #   tick-size    = 0.002 # the smallest price increment
  # }
  #
  # * Rules must be sorted in ascending order of "start-offset";
  # * A next rule should have greater "start-offset" than the previous one;
  #
  # Example:
  #
  # matching-rules = {
  #   "WAVES-8LQW8f7P5d5PZM7GtZEBgaqRPGSzS3DfPuiXrURJ4AJS": [
  #     {
  #       start-offset = 100
  #       tick-size    = 0.002
  #     },
  #     {
  #       start-offset = 500
  #       tick-size    = 0.0025
  #     },
  #     ...
  #   ]
  # }
  matching-rules = {}

  # Postgres connection settings
  postgres {
    server-name = "localhost"
    port-number = 5435
    database = ${waves.dex.postgres.user}
    user = "user"
    password = "user"
    data-source-class-name = "org.postgresql.ds.PGSimpleDataSource"
    application-name = ${waves.dex.id}
  }

  # History of the orders and their events, uses Postgres
  #
  #  Defaults:
  #
  #  batch-linger-ms = 1000
  #  batch-entries   = 10000
  #
  order-history {
    # Enable/disable order history
    enable = no
    # Time for delay between batches
    orders-batch-linger-ms = 1000
    # Etries count for the batch
    orders-batch-entries = 10000

    events-batch-linger-ms = 1000

    events-batch-entries = 10000
  }

  # Snapshots creation interval (in events)
  snapshots-interval = 1000000

  # During recovery determine the offset to start:
  # If the oldest snapshot has 2025331 offset, we start from startOldestOffset = truncate(2025331 / snapshots-interval * snapshots-interval) = 2000000.
  # This option allows to limit events from the newest snapshot also. For example, the newest snapshot was done at 3092345. startNewestOffset = 3092345 - limit-events-during-recovery
  # If this option is defined, the maximum wins = max(startOldestOffset, startNewestOffset), otherwise we start from startOldestOffset
  # limit-events-during-recovery = 2000000

  # Maximum time to recover all order books from snapshots
  snapshots-loading-timeout = 10m

  # Maximum time to recover events those observed at start
  start-events-processing-timeout = 20m

  # Maximum time to process recovered events by order books
  order-books-recovering-timeout = 10m

  # Settings for awaiting proper offsets in order to start handling new orders
  waiting-offset-tool {

    # Maximal time for restoring addresses initial balances and starting handle new orders
    # consider the following formula: (lo - co) / K <= T, where:
    # lo - last queue offset
    # co - current offset matcher processes
    # K - commands per second counted from the previous step
    # T - {waiting-queue.max-waiting-time} in seconds
    # when the condition becomes true, then Matcher can handle new commands
    # by default 20s, see https://doc.akka.io/docs/akka-http/current/common/timeouts.html#request-timeout
    max-waiting-time = ${akka.http.server.request-timeout}

    # uses only for comment in exception if timeout is reached;
    # do not change this setting: it will not change actual timeout
    queue-processing-timeout = ${waves.dex.start-events-processing-timeout}

    # Interval for checking that matcher is able to handle new commands in a queue
    check-interval = 5s
  }

  # Base assets used as price assets
  price-assets: []

  # Blacklisted assets id
  blacklisted-assets: []

  # Blacklisted assets name
  blacklisted-names: []

  # Blacklisted addresses
  blacklisted-addresses: []

  # * yes - only "allowed-asset-pairs" are allowed to trade. Other pairs are blacklisted.
  # * no  - "allowed-asset-pairs" are permitted to trade. If a pair is not in "allowed-asset-pairs",
  #         it's checked by "blacklisted-assets" and "blacklisted-names".
  white-list-only = no

  # Example:
  # allowed-asset-pairs = [
  #  "WAVES-8LQW8f7P5d5PZM7GtZEBgaqRPGSzS3DfPuiXrURJ4AJS"
  # ]
  allowed-asset-pairs: []

  # Set of allowed order versions
  allowed-order-versions = [1, 2, 3]

  # Settings for /matcher/orderbook/{amountAsset}/{priceAsset}?depth=N
  order-book-http {
    # Available depths for requests. When ?depth=3 is requested, returned a cache for depth of 10
    depth-ranges = [10, 100]

    # The default depth, when ?depth wasn't specified.
    # Effectively, the nearest bigger (or equal to default-depth) value will be selected from depth-ranges.
    # The maximum depth will be selected if null specified.
    default-depth = 100
  }

  # Queue for events (order was added, order was cancelled)
  events-queue {
    # Store events locally in LevelDB
    type = "local" # Other possible values: kafka

    local {
      # If "no" - no events will be written to the queue. Useful for debugging
      enable-storing = yes

      # Interval between reads from the disk
      polling-interval = 20ms

      # Max elements per poll
      max-elements-per-poll = 100

      # Clean old records before start consuming
      clean-before-consume = yes
    }

    kafka {
      # Kafka servers in format: host1:port1,host2:port2,...
      servers = ""

      # Where events should be written and read from
      topic = "dex-events"

      # There are should be different groups for different DEX connected to the same topic.
      group = "dex-server-0"

      # Consumer-related settings
      consumer {
        # The consumer is waiting for new messages in this duration. After this it retries. So there is a loop.
        fetch-max-duration = 30ms

        # A maximum number of polled messages in a buffer
        max-buffer-size = 1000

        # https://docs.confluent.io/current/installation/configuration/consumer-configs.html
        client {
          bootstrap.servers = ${waves.dex.events-queue.kafka.servers}

          # Useful for debugging and metrics
          client.id = "consumer"

          # An id of Kafka's group.
          group.id = ${waves.dex.events-queue.kafka.group}

          max.poll {
            # Max interval between two polls. If it exceeded, the consumer is considered failed
            interval.ms = 11000

            # The maximum number of records returned in a single call
            records = 100
          }

          # Wait before attempting to reconnect x ∊ [reconnect.backoff.ms; reconnect.backoff.max.ms]
          reconnect.backoff {
            ms = 2000
            max.ms = 4000
          }

          # The amount of time to wait before attempting to retry a failed request to a given topic partition
          retry.backoff.ms = 500

          # Disable storing offsets at Kafka. We do it ourselves
          auto.offset.reset = "earliest"
          enable.auto.commit = false

          # Close idle connections after
          connections.max.idle.ms = 30000
        }
      }

      # Producer-related settings
      producer {
        # If "no" - no events will be written to the queue. Useful for debugging
        enable = yes

        # https://docs.confluent.io/current/installation/configuration/producer-configs.html
        client {
          bootstrap.servers = ${waves.dex.events-queue.kafka.servers}

          # Useful for debugging and metrics
          client.id = "producer"

          # Wait responses from all kafka brokers
          acks = all

          # At Most Once semantics
          retries = 0

          # Buffer messages into a batch for this duration
          linger.ms = 10

          # Maximum size for batch
          batch.size = 204800

          # To guarantee the order
          max.in.flight.requests.per.connection = 1

          # A timeout for sending one message
          request.timeout.ms = 8000

          # A maximum timeout for sending one message. Note, max_retries = delivery.timeout.ms / request.timeout.ms
          delivery.timeout.ms = 9000

          # Wait before attempting to reconnect x ∊ [reconnect.backoff.ms; reconnect.backoff.max.ms]
          reconnect.backoff {
            ms = 2000
            max.ms = 4000
          }

          # The amount of time to wait before attempting to retry a failed request to a given topic partition
          retry.backoff.ms = 500

          compression.type = "none"

          # Close idle connections after
          connections.max.idle.ms = 10000
        }
      }
    }

    # Circuit breaker for a queue.
    # For now it is make sense in a case of kafka queue.
    # See https://doc.akka.io/docs/akka/current/common/circuitbreaker.html for more information.
    circuit-breaker {
      # Maximum number of failures before opening the circuit.
      max-failures = 10

      # Time after which a call is considered as failed.
      # The default value is based on kafka producer settings.
      call-timeout = ${waves.dex.events-queue.kafka.producer.client.delivery.timeout.ms}ms

      # Time after which to attempt to close the circuit.
      reset-timeout = 10s
    }
  }

  # Settings for transaction broadcaster
  exchange-transaction-broadcast {
    # * Bettween checks;
    # * A transaction will not be sent more frequently than this interval.
    interval = 7 seconds

    # Not sended transaction:
    # * Will be removed from queue after this timeout;
    # * A warning will be logged.
    max-pending-time = 15 minutes
  }

  # Web socket connections settings
  web-sockets {
    health-check {
      # Interval between ping messages sent to client
      ping-interval = 30s

      # Timeout for client response with the last payload.
      # That means matcher expects pong to the last sent ping. Outdated pongs will be ignored
      pong-timeout = 70s
    }

    # Settings for
    external-client-handler {
      # Interval between messages that will be sent to subscribers
      messages-interval = 100ms

      # Max connection lifetime before force stop
      max-connection-lifetime = 24h

      # A public key to validate JWT. The can be obtained from auth services
      jwt-public-key = """-----BEGIN PUBLIC KEY-----
-----END PUBLIC KEY-----"""

      subscriptions {
        # Max number of subscriptions to order books changes
        max-order-book-number = 10

        # Max number of subscriptions to addresses changes
        max-address-number = 10
      }

      health-check = ${waves.dex.web-sockets.health-check}
    }

    internal-broadcast {
      # Interval between messages that will be sent to subscribers
      messages-interval = 1s
    }

    internal-client-handler {
      health-check = ${waves.dex.web-sockets.health-check}
    }
  }
}

# Comparison tool.
# Used to compare two matchers. Useful during updates
waves.dex.comparison-tool {
  checks {
    # An interval between checks
    interval = 5s

    # A duration of checks
    duration = 10m

    # A number of failed comparisons in a row after which we get an error in logs
    strike = 4
  }

  # A list of REST API, e.g. ["http://127.0.0.1:6886", "https://new-matcher:6886"]
  # The data from the first matcher is used as reference during comparisons.
  matcher-rest-apis = []

  tradable-balance-check {
    # A list of base58-encoded public keys of accounts.
    # We use here public keys instead of addresses, because some endpoints require a public key.
    # Also it is easy to get an address from the public key, but it is hard to do the reverse conversion.
    account-pks = []

    # Check balance in this asset pairs.
    # E.g.: "WAVES-8LQW8f7P5d5PZM7GtZEBgaqRPGSzS3DfPuiXrURJ4AJS"
    asset-pairs = []
  }
}

# WARNING: No user-configurable settings below this line.

waves.dex {
  # Timeout for REST API responses from actors.
  # To change a timeout for all REST API responses, change this option and akka.http.server.request-timeout
  actor-response-timeout = ${akka.http.server.request-timeout}

  # Timeout to process consumed messages. Used in a back pressure
  process-consumed-timeout = 10 seconds

  # Size of the buffer of balance changes. Used in a back pressure
  waves-blockchain-client.balance-stream-buffer-size = 100

  address-actor {
    # Messages accumulation period for authenticated WS stream
    ws-messages-interval = ${waves.dex.web-sockets.external-client-handler.messages-interval}

    # Timeout of the batch orders cancel
    batch-cancel-timeout = 18 seconds # = 9/10 * actor-response-timeout, should be enough
  }

  # According to https://github.com/wavesplatform/protobuf-schemas/blob/master/proto/waves/transaction.proto
  # Transaction
  #   chain_id: 4 +
  #   sender_public_key: 32 +
  #   fee: Amount
  #     asset_id: 0 +
  #     amount: 8 +
  #   timestamp: 8 +
  #   version: 4 +
  #   exchange: ExchangeTransactionData
  #	   amount: 8 +
  #     price: 8 +
  #     buy_matcher_fee: 8 +
  #     sell_matcher_fee: 8 +
  #     orders: Order: 2 *
  #	     chain_id: 4 +
  #       sender_public_key: 32 +
  #       matcher_public_key: 32 +
  #       asset_pair: AssetPair:
  #         amount_asset_id: 0 +
  #         price_asset_id: 0 +
  #       order_side: 1 +
  #       amount: 8 +
  #       price: 8 +
  #       timestamp: 8 +
  #       expiration: 8 +
  #       matcher_fee: 0 + 8 +
  #       version: 4 +
  #       proofs: 32
  # The minimal size of exchange transaction of v3 is 376 bytes =
  #   4 + 32 + 0 + 8 + 8 + 4 + 8 + 8 + 8 + 8 + 2 * (4 + 32 + 32 + 0 + 0 + 1 + 8 + 8 + 8 + 8 + 0 + 8 + 3 + 32)
  #
  # According to https://docs.waves.tech/en/blockchain/block/
  # The maximum size of a block is 1MB = 1048576 bytes
  #
  # Thus ≈ 2789 exchange transactions fit into a block.
  # 2 blocks for this FifoSet is enough, because it is auxiliary functionality.
  order-events-coordinator-actor {
    exchange-transaction-cache-size = 6000
  }
}

waves.dex.cli {

  # Config paths to exclude (see ConfigChecker)
  # Can be executed by CLI command "check-config" and as a part of checking server in "check-server" command
  # Pay attention that property paths should be without waves.dex prefix
  ignore-unused-properties = [
    "root-directory",
    "events-queue.kafka.consumer.client",
    "events-queue.kafka.producer.client",
    "events-queue.kafka.servers",
    "events-queue.kafka.group"
  ]

  args-overrides {
    address-scheme-byte = ${waves.dex.address-scheme-character}
    dex-rest-api = ${waves.dex.rest-api.address}":"${waves.dex.rest-api.port}
    node-rest-api = ""
    auth-service-rest-api = ""
    timeout = 30 seconds
  }
}

akka {
  loggers = ["akka.event.slf4j.Slf4jLogger"]
  loglevel = "DEBUG" # | OFF | ERROR | WARNING | INFO
  logging-filter = "akka.event.slf4j.Slf4jLoggingFilter"

  actor {
    allow-java-serialization = off
    guardian-supervisor-strategy = "com.wavesplatform.dex.actors.RootActorSystem$EscalatingStrategy"

    deployment {
      "/exchange-transaction-broadcast" {
        dispatcher = "akka.actor.broadcast-dispatcher"
      }
      "/addresses/history-router/*" {
        dispatcher = "akka.actor.orders-history-dispatcher"
      }
    }

    broadcast-dispatcher {
      type = "Dispatcher"
      executor = "thread-pool-executor"
      thread-pool-executor.fixed-pool-size = 1
      throughput = 1
    }

    orders-history-dispatcher {
      type = "Dispatcher"
      executor = "thread-pool-executor"
      thread-pool-executor.fixed-pool-size = 1
      throughput = 1
    }

    grpc-dispatcher {
      type = "Dispatcher"
      executor = "thread-pool-executor"
      thread-pool-executor.fixed-pool-size = 4
      throughput = 10
    }

    leveldb-dispatcher {
      type = "Dispatcher"
      executor = "thread-pool-executor"
      # Otherwise we get sometimes sigsegv
      thread-pool-executor.fixed-pool-size = 1
      throughput = 1
    }

  }

  http {
    server {
      server-header = ""
      idle-timeout = 110s
      parsing.max-content-length = 100kB # https://github.com/lightbend/config/blob/master/HOCON.md#size-in-bytes-format
    }

    client.user-agent-header = ""
  }
}

# See scala.concurrent.ExecutionContext
scala.concurrent.context {
  minThreads = 2
  numThreads = "x1"
  maxThreads = "x1"
  maxExtraThreads = "256"
}

kanela {
  show-banner = no
}

kamon {
  enable = no

  modules {
    # We must setup this even we don't depend on apm-reporter due to a bug in Kamon
    apm-reporter {
      enabled = no
      name = "" # in order to fix warnings
      description = "" # in order to fix warnings
      factory = "" # in order to fix warnings
    }
    influxdb {
      # Set to "yes", if you want to report metrics
      enabled = no
    }
    jaeger {
      # Set to "yes", if you want to report traces
      enabled = no
    }
    status-page {
      # Set to "yes", if you want to enable status page
      enabled = no
    }
  }

  trace {
    tick-interval = 10 seconds

    # Size of the internal queue where sampled spans will stay until they get flushed. If the queue becomes full then
    # sampled finished spans will be dropped in order to avoid consuming excessive amounts of memory. Each configured
    # reporter has a separate queue.
    # see message "spans reported to jaeger"
    reporter-queue-size = 4096

    sampler = adaptive
    adaptive-sampler {
      throughput = 600
    }

    hooks {
      # WARNING: No user-configurable settings below this line.
      pre-finish += "com.wavesplatform.dex.tool.KamonTraceUtils$FilteringRejectedHook"
    }
  }

  jaeger {
    protocol = http
    http-url = "http://192.168.1.64:14268/api/traces"
    include-environment-tags = yes
  }

  # copies header "x-trace-id" if it exists in Kamon.currentContext as a tag
  propagation.http.default.tags.mappings {
    x-trace-id = "x-trace-id"
  }

  instrumentation {
    # WARNING: No user-configurable settings below this line.
    akka.http {
      server {
        propagation {
          enabled = yes
        }
        metrics {
          enabled = no
        }
        tracing {
          enabled = yes
          span-metrics = off

          # takes tag x-trace-id from Kamon.currentContext if it exists
          # and uses it as a current trace-id
          preferred-trace-id-tag = x-trace-id

          # adds response headers x-span-id, x-trace-id
          response-headers {
            trace-id = "x-trace-id"
            span-id = "x-span-id"
          }
        }
      }

      client {
        propagation {
          enabled = yes
        }
        tracing {
          enabled = yes
          span-metrics = off
        }
      }
    }
  }

  # A node identification
  environment {
    service = "DEX"

    # An unique id of your node to distinguish it from others
    # host = ""
  }

  metric {
    # An interval within metrics are aggregated. After it, them will be sent to the server
    tick-interval = 20 seconds

    optimistic-tick-interval = no

    factory.default-settings.timer {
      lowest-discernible-value = 1000000 # 1 millisecond
      highest-trackable-value = 200000000000 # 200 seconds
      significant-value-digits = 0
    }

  }

  # Reporter settings
  influxdb {
    hostname = "127.0.0.1"
    port = 8086
    database = "mydb"

    # authentication {
    #   user = ""
    #   password = ""
    # }
  }
}

include "local.conf"
